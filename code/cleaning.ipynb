{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7f4ec98-eb68-4f46-bffc-e028d579a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_json = pd.read_json(r'C:\\Users\\razor\\Desktop\\NLP Assignment\\NLPoutput.json', lines = True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "216bb328-091c-4c41-b498-c62de6ea522f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': ['Name'],\n",
       "  'points': [{'start': 200, 'end': 212, 'text': 'Jun Wai Chin'}]},\n",
       " {'label': ['CollegeName'],\n",
       "  'points': [{'start': 237,\n",
       "    'end': 274,\n",
       "    'text': 'Tunku Abdul Rahman University College'}]},\n",
       " {'label': ['GraduationYear'],\n",
       "  'points': [{'start': 609, 'end': 613, 'text': '2022'}]},\n",
       " {'label': ['YearsofExperience'],\n",
       "  'points': [{'start': 469, 'end': 477, 'text': '3 months'}]},\n",
       " {'label': ['CompaniesWorkAt'],\n",
       "  'points': [{'start': 399, 'end': 404, 'text': 'Tapod'}]},\n",
       " {'label': ['Location'],\n",
       "  'points': [{'start': 275, 'end': 288, 'text': 'Petaling Jaya'}]},\n",
       " {'label': ['Skills'],\n",
       "  'points': [{'start': 76, 'end': 92, 'text': 'Machine Learning'}]},\n",
       " {'label': ['Skills'], 'points': [{'start': 93, 'end': 99, 'text': 'Python'}]},\n",
       " {'label': ['Skills'],\n",
       "  'points': [{'start': 123, 'end': 131, 'text': 'Teamwork'}]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json.iloc[1].annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3746efa-25a2-435f-a460-d422baec8382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Contact www.linkedin.com/in/hongong (LinkedIn)...\n",
       "1    Contact www.linkedin.com/in/jun-wai- chin-Ob80...\n",
       "2    Contact www.linkedin.com/in/mark-tan-bc (Linke...\n",
       "3    Contact www.linkedin.com/in/lohys68 (LinkedIn)...\n",
       "4    Contact www.linkedin.com/in/adi-zafri- bOba6a1...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json[\"content\"] = data_json[\"content\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n",
    "data_json[\"content\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c402c308-a18b-48c0-be4e-a649e42ce2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "# JSON formatting functions\n",
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    training_data = []\n",
    "    lines=[]\n",
    "    with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        text = data['content'].replace(\"\\n\", \" \")\n",
    "        entities = []\n",
    "        data_annotations = data['annotation']\n",
    "        if data_annotations is not None:\n",
    "            for annotation in data_annotations:\n",
    "                #only a single point in text annotation.\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    point_start = point['start']\n",
    "                    point_end = point['end']\n",
    "                    point_text = point['text']\n",
    "\n",
    "                    lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
    "                    rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
    "                    if lstrip_diff != 0:\n",
    "                        point_start = point_start + lstrip_diff\n",
    "                    if rstrip_diff != 0:\n",
    "                        point_end = point_end - rstrip_diff\n",
    "                    entities.append((point_start, point_end + 1 , label))\n",
    "        training_data.append((text, {\"entities\" : entities}))\n",
    "    return training_data\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae29b87-9bdf-4c16-924e-c5962c71af2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contact www.linkedin.com/in/jia-qing- poh-21a816190 (LinkedIn) Top Skills Critical Thinking Problem Solving Microsoft Excel Languages Mandarin (Full Professional) Malay (Limited Working) English (Native or Bilingual) Jia Qing Poh Statistical Data Science student and aspiring data scientist Kiang Experience AXA Affin Insurance Data Analyst Intern May 2021 - August 2021 (4 months) SOLIDHWUM Vice President November 2019 - May 2020 (7 months) Education Heriot-Watt University Bachelor of Science - BSc, Statistical Data Science * (2019 - 2022) Methodist College Kuala Lumpur A Levels Sekolah Sri Acmar SPM Page 1 of 1',\n",
       " {'entities': [[217, 229, 'Name'],\n",
       "   [453, 475, 'CollegeName'],\n",
       "   [372, 381, 'YearsofExperience'],\n",
       "   [308, 327, 'CompaniesWorkAt'],\n",
       "   [8, 51, 'Email'],\n",
       "   [74, 91, 'Skills'],\n",
       "   [92, 107, 'Skills'],\n",
       "   [108, 123, 'Skills']]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trim_entity_spans(convert_dataturks_to_spacy(r'C:\\Users\\razor\\Desktop\\NLP Assignment\\NLPoutput.json'))\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9af01449-31dc-40f3-a231-6cb2e1c2f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entities(training_data):\n",
    "    \n",
    "    clean_data = []\n",
    "    for text, annotation in training_data:\n",
    "        \n",
    "        entities = annotation.get('entities')\n",
    "        entities_copy = entities.copy()\n",
    "        \n",
    "        # append entity only if it is longer than its overlapping entity\n",
    "        i = 0\n",
    "        for entity in entities_copy:\n",
    "            j = 0\n",
    "            for overlapping_entity in entities_copy:\n",
    "                # Skip self\n",
    "                if i != j:\n",
    "                    e_start, e_end, oe_start, oe_end = entity[0], entity[1], overlapping_entity[0], overlapping_entity[1]\n",
    "                    # Delete any entity that overlaps, keep if longer\n",
    "                    if ((e_start >= oe_start and e_start <= oe_end) \\\n",
    "                    or (e_end <= oe_end and e_end >= oe_start)) \\\n",
    "                    and ((e_end - e_start) <= (oe_end - oe_start)):\n",
    "                        entities.remove(entity)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        clean_data.append((text, {'entities': entities}))\n",
    "                \n",
    "    return clean_data\n",
    "\n",
    "data = clean_entities(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a45934b-2088-415b-bed0-42c6f2149ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Contact www.linkedin.com/in/mohamsup (LinkedIn) Top Skills Microsoft Office Sony Vegas Adobe Premiere Pro Languages Malay (Native or Bilingual) English (Native or Bilingual) Arabic (Limited Working) Bengali (Native or Bilingual) Honors-Awards Dean's List Certificates IIUM Academic Excellence Award IIUM Academic Excellence Award IIUM Ummatic Scholarship UG IIUM Ummatic Scholarship UG Mohammad Bin Yousuf Data Scientist I Data Science I Machine Learning I Artificial intelligence I Big Data Analytics Kuala Lumpur Summary Seeking a Machine Learning Engineer position with a background in Computer Science, focusing on Data Science and Artificial Intelligence. Currently completing a bachelor's in computer science at IIUM. Experienced as a Data Visualization analyst intern at Schlumberger. Experienced in projects related to Data Science, Machine Learning & Cryptocurrency. Acquired additional knowledge in Machine Learning via online certificate courses. Experience Schlumberger Data Visualization Analyst January 2020 - September 2020 (9 months) Petaling Jaya, Selangor, Malaysia Responsibilities: * Helps with data visualization in the Global Business Services, Data & Analytics Department. * Catered to global data services while stationed at the Kuala Lumpur Financial Hubs (KLFH). * Extracting and manipulating data with ETL tools. * Building Macros to automate tedious tasks. * Developing workflows that ensures the standards of Power BI Visualizations. * Data troubleshooting and monitoring; ensuring data quality and integrity. * Creating queries using SQL to monitor massive databases and extract relevant data. * Training to collect, analyze and disseminate information with accuracy. * Understand the behind-the-scenes of Data Architecture. * Working with team that supports the data needs of multiple teams, systems and product lines. Page 1 of 2 Elmangos Part-Time Web Developer June 2017 - June 2017 (1 month) Kuala Lumpur, Malaysia Education International Islamic University Malaysia (HUM) Master's degree, Master of Business Intelligence & Analytics - (October 2020 - December 2021) International Islamic University Malaysia (HUM) Bachelor's degree, Bachelor of Science (Honors) in Computer Science - (September 2016 - September 2020) International Islamic University Malaysia (HUM) Foundation degree, Engineering * (October 2014 - July 2016) International Islamic School Malaysia IGCSEs, Sciences - (2012 - 2014) Page 2 of 2\",\n",
       " {'entities': [[386, 405, 'Name'],\n",
       "   [1040, 1049, 'YearsofExperience'],\n",
       "   [778, 791, 'CompaniesWorkAt'],\n",
       "   [8, 36, 'Email'],\n",
       "   [502, 514, 'Location'],\n",
       "   [59, 75, 'Skills'],\n",
       "   [76, 86, 'Skills'],\n",
       "   [87, 105, 'Skills']]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504597e-567a-4b2f-96e9-02d02ca8a6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
